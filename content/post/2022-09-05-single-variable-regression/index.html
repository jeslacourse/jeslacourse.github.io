---
title: "Simple Linear Regression"
author: ''
date: "2022-09-05"
draft: no
slug: /regression/
categories: regression
description: ''
---



<blockquote>
<p>One predictor, one outcome</p>
</blockquote>
<p><strong>Linear Regression:</strong> The measure of lineal relationship between two variables.</p>
<p>Simple regression will have one continuous response variable (y) and one continuous explanatory variable (x). Response variables are also known as the <em>dependent</em> or <em>outcome</em> variable. Explanatory variables, aka <em>independent</em>, <em>predictor</em>, or <em>covariate</em> variables, can include categorical values.</p>
<p><span class="math display">\[y=\beta_0 + \beta_1x\]</span>
Where <span class="math inline">\(\beta_0\)</span> is the y-intercept and <span class="math inline">\(\beta_1\)</span> is the slope of the function.</p>
<div id="modeling" class="section level2">
<h2>Modeling</h2>
<p><code>X</code> is treated as a fixed variable whose values have been chosen by the researcher. Though it should be noted that regression is often used where variable is not wholly chosen. For example, sampling a population will return a distribution of ages that may not match the true distribution of the population. So <code>X</code> is also, technically, random.</p>
<p><code>Y</code> is a random variable</p>
<p>Our regression model dependency of <code>Y</code> on <code>X</code>
esti
<span class="math display">\[Y=\beta_0 + \beta_1X + \epsilon\]</span>
<span class="math inline">\(\beta\)</span>’s and <code>X</code> are considered fixed values, with random variable <span class="math inline">\(\epsilon\)</span>.</p>
<p>Where <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are parameters; usually unknown values related to the population and not the sample.</p>
<ul>
<li>parameter: values for the population</li>
<li>statistic: values for the sample</li>
</ul>
<blockquote>
<p>We are using statistics to estimate our parameters</p>
</blockquote>
<p>After collecting data from the population, we can create a sample on which to run our statistics for which we can estimate our parameters.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>parameter</th>
<th>statistic</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>mean</td>
<td></td>
<td>{y}</td>
</tr>
<tr class="even">
<td>variance</td>
<td>^2</td>
<td>s^2</td>
</tr>
<tr class="odd">
<td>slope</td>
<td>_1</td>
<td>b_1</td>
</tr>
<tr class="even">
<td>intercept</td>
<td>_0</td>
<td>b_0</td>
</tr>
</tbody>
</table>
</div>
<div id="utility" class="section level2">
<h2>Utility</h2>
<p>Regression is used for:</p>
<ol style="list-style-type: decimal">
<li>Observational studies</li>
</ol>
<ul>
<li>just observe, no manipulation</li>
<li>treatment is not randomized</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Experimental studies</li>
</ol>
<ul>
<li>manipulate the explanatory variables</li>
<li>treatment must be randomized</li>
</ul>
<p>(!) Correlations is not equal to causation in non-random studies</p>
</div>
<div id="expected-values" class="section level2">
<h2>Expected Values</h2>
<p>For a <strong>discrete</strong> random variable <code>Y</code> with possible values <span class="math inline">\(y_1... y_k\)</span> we can say:
<span class="math display">\[ E(Y) = \Sigma_{i=1}^k y_1 P(Y = y_i)\]</span>
where <span class="math inline">\(E(Y)\)</span> is a weighted average of the possible values <span class="math inline">\(y_1... y_k\)</span> and the weights <span class="math inline">\(P(Y = y_1)...P(Y = y_k)\)</span> are the expected probabilities. This will give us a weighted average.</p>
<p>Weighted Average:
<span class="math display">\[\Sigma_{i=1}^k w_ia_i\]</span>
If <span class="math inline">\(\Sigma w_i = 1\)</span> and <span class="math inline">\(0 \leq w_1 \leq 1\)</span>.</p>
<p>A <strong>continuous</strong> random variable <code>Y</code> would be represented by a density function:</p>
<p><span class="math display">\[E(Y) = \int_{-\infty}^{\infty} yf(y)dy\]</span>
For example, the normal distribution <code>Y ~ N(0,1)</code> with mean <code>0</code> and variance <code>1</code>, would be represented using the density function:</p>
<p><span class="math display">\[E(Y) = \int_{-\infty}^{\infty}y\frac{1}{\sqrt{2\pi}}
  \exp\left( -\frac{y^2}{2}\right) dy = 0 \]</span></p>
<p>The <strong>population mean</strong> is the expected value. If <span class="math inline">\(Z_1..Z_N\)</span> for all values in the population, then we would use the parameter:</p>
<p><span class="math display">\[ E(Z) = \frac{1}{N}\Sigma_{i=1}^N Z_i\]</span></p>
<p><strong>Sample means</strong> are averages. Given the sample data <span class="math inline">\(X_1... X_n\)</span>, would return the <em>statistic</em>:</p>
<p><span class="math display">\[ \bar{x}  = \frac{1}{n} \Sigma_{i = 1}^nX_i\]</span></p>
</div>
<div id="variance" class="section level2">
<h2>Variance</h2>
<p>We can use the <strong>population variance</strong> formula to show that <span class="math inline">\(E(Y)\)</span> is equivalent to the parameter <span class="math inline">\(\mu\)</span>. Given the population variance <span class="math inline">\(var(Y)\)</span>:</p>
<p><span class="math display">\[ var(Y) = E[Y-E(Y)]^2\\=E[Y-\mu]^2\\\therefore \mu = E(Y)\]</span></p>
<p>The squaring of <span class="math inline">\([Y-E(Y)]\)</span> “removes the sign”, reverting all distances to positive distances from the mean.</p>
<p>Given our known substitutions, we can say:</p>
<p><span class="math display">\[ var(Y) = E[Y-E(Y)]^2\\=\Sigma_{i=1}^k (y_i-\mu)^2P(Y-y_i)\]</span></p>
<p>If <span class="math inline">\(Z_1... Z_n\)</span> account for all values in a population, we would have parameter:</p>
<p><span class="math display">\[var(Z) = \frac{1}{N}\Sigma_{i=1}^{N}(Z_i-\bar{Z})^2\]</span></p>
<p>where <span class="math inline">\(\bar{Z} = E(Z)\)</span>.</p>
<p>Sample data <span class="math inline">\(x_i...x_n\)</span> would give us the <strong>unbiased sample variance</strong>:</p>
<p><span class="math display">\[s^2 = \frac{\Sigma(x_i - \bar{x})^2}{n-1}\]</span></p>
<p>Focusing on the denominator, sample sizes <span class="math inline">\(n\)</span> will shift the statistic significantly compared to if the sample was larger.</p>
</div>
<div id="bias" class="section level2">
<h2>Bias</h2>
<p>Because of random variability, <span class="math inline">\(s^2\)</span> will vary with each experiment. An unbiased sample variance is an average value of those experiments.</p>
<p><span class="math display">\[ E(s^2) = E\frac{\Sigma(Y_i-\bar{Y})^2}{n-1}= var(Y)\]</span></p>
</div>
