---
title: Model Fit and Residuals with R
author: Jes LaCourse
date: '2022-11-13'
slug: [ErrorsResiduals]
categories: []
tags: ['regression', 'plotly', 'ggplot', 'dataviz', 'rstats']
summary: 'Reading `lm()` outputs and residual analysis for linear models'
---

<script src="{{< blogdown/postref >}}index_files/kePrint/kePrint.js"></script>
<link href="{{< blogdown/postref >}}index_files/lightable/lightable.css" rel="stylesheet" />


<div id="a-quick-recap" class="section level1">
<h1>A Quick Recap</h1>
<table style="color:white; font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;" class=" lightable-paper">
<caption>
<span id="tab:createSample">Table 1: </span>Blood Pressure Sample
</caption>
<tbody>
<tr>
<td style="text-align:left;">
Person
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
2
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
5
</td>
<td style="text-align:left;">
6
</td>
<td style="text-align:left;">
7
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:left;">
9
</td>
<td style="text-align:left;">
10
</td>
<td style="text-align:left;">
11
</td>
<td style="text-align:left;">
12
</td>
<td style="text-align:left;">
13
</td>
<td style="text-align:left;">
14
</td>
<td style="text-align:left;">
15
</td>
<td style="text-align:left;">
16
</td>
<td style="text-align:left;">
17
</td>
<td style="text-align:left;">
18
</td>
<td style="text-align:left;">
19
</td>
<td style="text-align:left;">
20
</td>
</tr>
<tr>
<td style="text-align:left;">
Age
</td>
<td style="text-align:left;">
58
</td>
<td style="text-align:left;">
46
</td>
<td style="text-align:left;">
56
</td>
<td style="text-align:left;">
37
</td>
<td style="text-align:left;">
23
</td>
<td style="text-align:left;">
30
</td>
<td style="text-align:left;">
20
</td>
<td style="text-align:left;">
25
</td>
<td style="text-align:left;">
31
</td>
<td style="text-align:left;">
50
</td>
<td style="text-align:left;">
34
</td>
<td style="text-align:left;">
27
</td>
<td style="text-align:left;">
22
</td>
<td style="text-align:left;">
52
</td>
<td style="text-align:left;">
20
</td>
<td style="text-align:left;">
42
</td>
<td style="text-align:left;">
20
</td>
<td style="text-align:left;">
58
</td>
<td style="text-align:left;">
24
</td>
<td style="text-align:left;">
35
</td>
</tr>
<tr>
<td style="text-align:left;">
BP
</td>
<td style="text-align:left;">
167
</td>
<td style="text-align:left;">
136
</td>
<td style="text-align:left;">
116
</td>
<td style="text-align:left;">
116
</td>
<td style="text-align:left;">
101
</td>
<td style="text-align:left;">
121
</td>
<td style="text-align:left;">
103
</td>
<td style="text-align:left;">
101
</td>
<td style="text-align:left;">
105
</td>
<td style="text-align:left;">
158
</td>
<td style="text-align:left;">
117
</td>
<td style="text-align:left;">
118
</td>
<td style="text-align:left;">
113
</td>
<td style="text-align:left;">
148
</td>
<td style="text-align:left;">
105
</td>
<td style="text-align:left;">
142
</td>
<td style="text-align:left;">
89
</td>
<td style="text-align:left;">
153
</td>
<td style="text-align:left;">
122
</td>
<td style="text-align:left;">
135
</td>
</tr>
</tbody>
</table>
<p>We’re looking at the relationship between blood pressure samples and age. For this study, we have 20 people ranging in age between 20 and 58. Our median age is 32.5; mean age is a little higher at 35.5. We also determined that the blood pressure samples are evenly distributed.</p>
<p>We found evidence that our linear model was underestimating blood pressure rates for older participants. There was also an individual, <code>Person 3 (56,113)</code>, whose blood pressure was substantially lower than expected.</p>
</div>
<div id="model-fit" class="section level1">
<h1>Model Fit</h1>
<p>This article is all about the summary read out. Let’s take another look at the summary data for our model:</p>
<pre class="r"><code>summary(m)</code></pre>
<pre><code>## 
## Call:
## lm(formula = BP ~ Age, data = data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -34.248  -6.525   1.099   8.124  15.639 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  76.6333     7.9199   9.676 1.48e-08 ***
## Age           1.3146     0.2091   6.288 6.28e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 12.36 on 18 degrees of freedom
## Multiple R-squared:  0.6872, Adjusted R-squared:  0.6698 
## F-statistic: 39.54 on 1 and 18 DF,  p-value: 6.284e-06</code></pre>
<p>R modeling stores a handful of features with the saved variable, these can be accessed by calling <code>names(m)</code>. We used the coefficients in the last article, now we’ll take a look at attributes that give us a better look at how well our model fits the data.</p>
<pre class="r"><code>names(m)</code></pre>
<pre><code>##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;</code></pre>
<div id="residuals" class="section level2">
<h2>Residuals</h2>
<p>Our residuals, or differences between the estimated and actual blood pressure measurements, range from an overestimate of 34.2 mmHg, to an underestimate of 15.6 mmHg. The median residual is 1.1mmHg, a slight underestimate. We can determine which residuals belong to a sample by calling <code>resid(m)</code>, the equivalent of <code>m$residuals</code>. Our min and max residuals belong to <code>Person 3</code> and <code>Person 10</code>, respectively.</p>
<table style="color:white; font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;" class=" lightable-paper">
<caption>
<span id="tab:modelResid">Table 2: </span>Blood Pressure Sample
</caption>
<thead>
<tr>
<th style="text-align:right;">
1
</th>
<th style="text-align:right;">
2
</th>
<th style="text-align:right;">
3
</th>
<th style="text-align:right;">
4
</th>
<th style="text-align:right;">
5
</th>
<th style="text-align:right;">
6
</th>
<th style="text-align:right;">
7
</th>
<th style="text-align:right;">
8
</th>
<th style="text-align:right;">
9
</th>
<th style="text-align:right;">
10
</th>
<th style="text-align:right;">
11
</th>
<th style="text-align:right;">
12
</th>
<th style="text-align:right;">
13
</th>
<th style="text-align:right;">
14
</th>
<th style="text-align:right;">
15
</th>
<th style="text-align:right;">
16
</th>
<th style="text-align:right;">
17
</th>
<th style="text-align:right;">
18
</th>
<th style="text-align:right;">
19
</th>
<th style="text-align:right;">
20
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
14.12
</td>
<td style="text-align:right;">
-1.1
</td>
<td style="text-align:right;">
-34.25
</td>
<td style="text-align:right;">
-9.27
</td>
<td style="text-align:right;">
-5.87
</td>
<td style="text-align:right;">
4.93
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
-8.5
</td>
<td style="text-align:right;">
-12.38
</td>
<td style="text-align:right;">
15.64
</td>
<td style="text-align:right;">
-4.33
</td>
<td style="text-align:right;">
5.87
</td>
<td style="text-align:right;">
7.45
</td>
<td style="text-align:right;">
3.01
</td>
<td style="text-align:right;">
2.08
</td>
<td style="text-align:right;">
10.16
</td>
<td style="text-align:right;">
-13.92
</td>
<td style="text-align:right;">
0.12
</td>
<td style="text-align:right;">
13.82
</td>
<td style="text-align:right;">
12.36
</td>
</tr>
</tbody>
</table>
<p>These values may be difficult to read on their own, so I’ll add them back to our dataframe and visualize.</p>
<pre class="r"><code>data$Predicted &lt;- predict(m)
data$Residuals &lt;- resid(m)</code></pre>
<p>We can now match up the residuals in the table above with the estimates in the figure below. For the figure below, black dots are the actual values, while the black rings along the regression line are the estimated values given the subject’s age. <code>Person 3</code> and <code>Person 10</code> are not well estimated, while <code>Person 2</code>, <code>7</code>, <code>14</code>, and <code>18</code> have a much smaller residual error.</p>
<div class="figure"><span style="display:block;" id="fig:plotResid"></span>
<img src="{{< blogdown/postref >}}index_files/figure-html/plotResid-1.png" alt="Residuals: Over- and Underestimates of Blood Pressure" width="672" />
<p class="caption">
Figure 1: Residuals: Over- and Underestimates of Blood Pressure
</p>
</div>
</div>
<div id="residual-standard-error-rse" class="section level2">
<h2>Residual Standard Error (RSE)</h2>
<p>The RSE is a standard deviation estimate for linear regression. Smaller values tend to mean a better fit, while an RSE of zero (our estimates perfectly predict our values) would certainly mean our model has been <em>overfit</em>.</p>
<p><span class="math display">\[RSE = \sqrt{SSE/df_R}\]</span>
The residual standard error is the square root value of the sum of squared errors (SSE) divided by the residual degrees of freedom (df). Squaring residuals eliminates the sign (<span class="math inline">\(\pm\)</span>, for an over- or underfit). Taking the mean of residuals otherwise would simply give us a value at or near zero as over- and underestimates cancel each other out. Given 20 samples and 1 parameter (<code>Age</code>), we’ll calculate the degrees of freedom using <span class="math inline">\(df_R = n - p - 1\)</span> or <span class="math inline">\(df_R = 20 - 1 - 1 = 18\)</span>.</p>
<pre class="r"><code>SSE &lt;- sum(resid(m)^2)                             # 2751.189
df &lt;- length(m$residuals) - length(m$coefficients) # 18

RSE &lt;- sqrt(SSE/df)   #12.363</code></pre>
</div>
<div id="multiple-r-squared" class="section level2">
<h2>Multiple R-squared</h2>
<p>Multiple R-Squared and the Adjusted R-squared focus on correlation in our model. Correlation can range from -1 to 1, with values closer to -1 or 1 resulting in high correlation. For our data, we have a correlation value of 0.829 (<code>cor(Age,BP)</code>) which gives us a multiple R-squared value of 0.687. Adjusted R-squared values are calculated to account for increased variance with multiple parameters and tend to be more conservative. As such, Adjusted R-squared values are particularly useful for models with several parameters.</p>
<pre class="r"><code>cor(data$Age, data$BP)^2  # 0.687</code></pre>
</div>
<div id="f-statistics" class="section level2">
<h2>F-statistics</h2>
<p>Linear modeling in R uses t-testing and F-statistics to determine if any coefficients significantly influence our dependent variable. In our case, we are testing out whether <code>Age</code> influences <code>BP</code>. In short, a p-value <code>&lt; 0.05</code> would tell us that <code>Age</code> is a significant coefficient at <span class="math inline">\(\alpha = 0.05\)</span>. In our case, we can see that the p-value for <code>Age</code> is <code>&lt; 0.001</code>; there is a relationship between age and blood pressure.</p>
<pre class="r"><code>pvals &lt;- summary(m)$coefficients[,4]  # 6.28e-06 </code></pre>
</div>
<div id="in-summary" class="section level2">
<h2>In Summary</h2>
<p>The <code>summary()</code> feature provides critical feedback about the relationship between our dependent variable, <code>BP</code> and our coefficient or independent variable, <code>Age</code>. While not perfect, we have a relatively good model for predicting blood pressure.</p>
<p>The next post will look at how to improve our model fit. We’ll use R’s built in diagostics to determine the impact of outliers, sample size, and variance within the data.</p>
</div>
</div>
